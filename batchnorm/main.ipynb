{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6846522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem: internal covariate shift\n",
    "# Solution: address this problem with normalizing layer inputs\n",
    "# this method draws its strength from making normalization a part of the model \n",
    "# archietecture and performing the normalization for each training mini-batch.\n",
    "# BN allows to use much higher learning rates and be less careful about initialization\n",
    "# it alos acts as a regularizer, in some case eliminating the need for Dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40504da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original mini-batch: [ 2.1  4.3 -1.2  0.8  3.5 -0.3  1.7  2.9]\n",
      "\n",
      "Step 1 - Compute Statistics:\n",
      "  Mean (μ): 1.725\n",
      "  Variance (σ²): 3.102\n",
      "\n",
      "Step 2 - Normalize:\n",
      "  Normalized values: [ 0.213  1.462 -1.661 -0.525  1.008 -1.15  -0.014  0.667]\n",
      "  Check - Mean of normalized: 0.000\n",
      "  Check - Variance of normalized: 1.000\n",
      "\n",
      "Step 3 - Scale (γ) and Shift (β):\n",
      "  γ = 1.2, β = 0.5\n",
      "  Final output: [ 0.756  2.254 -1.493 -0.13   1.709 -0.88   0.483  1.301]\n"
     ]
    }
   ],
   "source": [
    "# Create a sample mini-batch (size=8 for clarity)\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "mini_batch = np.array([2.1, 4.3, -1.2, 0.8, 3.5, -0.3, 1.7, 2.9])\n",
    "print(\"Original mini-batch:\", mini_batch)\n",
    "print()\n",
    "\n",
    "# Step 1: Compute mean and variance\n",
    "mean = np.mean(mini_batch)\n",
    "variance = np.var(mini_batch)\n",
    "print(f\"Step 1 - Compute Statistics:\")\n",
    "print(f\"  Mean (μ): {mean:.3f}\")\n",
    "print(f\"  Variance (σ²): {variance:.3f}\")\n",
    "print()\n",
    "\n",
    "# Step 2: Normalize\n",
    "epsilon = 1e-8\n",
    "normalized = (mini_batch - mean) / np.sqrt(variance + epsilon)\n",
    "print(\"Step 2 - Normalize:\")\n",
    "print(\"  Normalized values:\", np.round(normalized, 3))\n",
    "print(f\"  Check - Mean of normalized: {np.mean(normalized):.3f}\")\n",
    "print(f\"  Check - Variance of normalized: {np.var(normalized):.3f}\")\n",
    "print()\n",
    "\n",
    "# Step 3: Scale and shift\n",
    "gamma = 1.2  # Learned parameter\n",
    "beta = 0.5   # Learned parameter\n",
    "output = gamma * normalized + beta\n",
    "print(\"Step 3 - Scale (γ) and Shift (β):\")\n",
    "print(f\"  γ = {gamma}, β = {beta}\")\n",
    "print(\"  Final output:\", np.round(output, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e359c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09489217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
